{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "k9tVBALkoT8L"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from skimage.feature import hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IQQfKRQBDUmz",
    "outputId": "2bca57c4-7813-4e53-b99b-6446d168e96f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "sjhJorVWocBf"
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (48,48)\n",
    "BATCH_SIZE = 64\n",
    "SAMPLES_PER_CLASS_TRAIN = 3000\n",
    "SAMPLES_PER_CLASS_TEST = 571"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "5zu-Hcf4ofzi"
   },
   "outputs": [],
   "source": [
    "data_train = r\"C:\\KULIAH SEMESTER 3\\Kecerdasan Artifisial\\FER 2013\\train\"\n",
    "data_test = r\"C:\\KULIAH SEMESTER 3\\Kecerdasan Artifisial\\FER 2013\\test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "f7sM7zIErF_Y"
   },
   "outputs": [],
   "source": [
    "def load_dataset_with_undersampling_and_hog(directory, samples_per_class):\n",
    "    images_hog = []\n",
    "    labels = []\n",
    "    for label in os.listdir(directory):\n",
    "        label_path = os.path.join(directory, label)\n",
    "        if os.path.isdir(label_path):\n",
    "            # List semua file dalam direktori kelas ini\n",
    "            image_files = os.listdir(label_path)\n",
    "            # Lakukan undersampling\n",
    "            sampled_files = random.sample(image_files, min(samples_per_class, len(image_files)))\n",
    "            for image_file in sampled_files:\n",
    "                image_path = os.path.join(label_path, image_file)\n",
    "                # Baca gambar dalam grayscale dan resize\n",
    "                image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "                image = cv2.resize(image, IMAGE_SIZE)\n",
    "\n",
    "                # Ekstraksi fitur HOG\n",
    "                hog_features = hog(\n",
    "                    image,\n",
    "                    orientations=9,  # Jumlah orientasi (bin)\n",
    "                    pixels_per_cell=(8, 8),  # Ukuran sel\n",
    "                    cells_per_block=(2, 2),  # Ukuran blok\n",
    "                    block_norm='L2-Hys',  # Normalisasi blok\n",
    "                    visualize=False  # Tidak menghasilkan gambar visualisasi\n",
    "                )\n",
    "                images_hog.append(hog_features)\n",
    "                labels.append(label)\n",
    "    return np.array(images_hog), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "mbD3zQrArY7n"
   },
   "outputs": [],
   "source": [
    "x_train, y_train = load_dataset_with_undersampling_and_hog(data_train, SAMPLES_PER_CLASS_TRAIN)\n",
    "x_test, y_test = load_dataset_with_undersampling_and_hog(data_test, SAMPLES_PER_CLASS_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kF559wcqv8NJ",
    "outputId": "ae5fa55b-8ae2-4b23-a982-565c4df9202e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18436, 900)\n",
      "(18436,)\n",
      "(3537, 900)\n",
      "(3537,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "qD2pIUo20NE_"
   },
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], -1)\n",
    "x_test = x_test.reshape(x_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AHsjUvtk0VOd"
   },
   "outputs": [],
   "source": [
    "print(x_train.shape[0], y_train_encoded.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7lUMPrNp0OHc",
    "outputId": "478f8cd3-dedb-4d42-a407-23036c96a7fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18436, 900)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "z-DcIA1treIn"
   },
   "outputs": [],
   "source": [
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "TwGwhzFe-u8f"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3x2bSZSX54OF",
    "outputId": "2bf29d5e-5331-4e0b-e801-745811f87522"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 6, 6, 6], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VDVdVoVcjz0R",
    "outputId": "c695bdad-ef8f-4321-bdd1-908a57d4403a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18436, 900, 1)\n",
      "(3537, 900, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.expand_dims(x_train, axis=-1)\n",
    "x_test = np.expand_dims(x_test, axis=-1)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wMaPqeBy_m9y",
    "outputId": "b636a215-4b0a-48c2-e8a1-5b18f0b06ebe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k0KfQAOUBQIf",
    "outputId": "662da27d-5894-4a09-995b-247ffafce7b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18436, 900)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_flatten = x_train.reshape(len(x_train), -1)\n",
    "x_test_flatten = x_test.reshape(len(x_test), -1)\n",
    "\n",
    "x_train_flatten.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "kScyQ1jqYd-C"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, feature=None, threshold=None, data_left=None, data_right=None, gain=None, value=None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.data_left = data_left\n",
    "        self.data_right = data_right\n",
    "        self.gain = gain\n",
    "        self.value = value\n",
    "\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, min_samples_split=2, max_depth=5):\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.root = None\n",
    "\n",
    "    @staticmethod\n",
    "    def _entropy(s):\n",
    "        counts = np.bincount(np.array(s, dtype=int))\n",
    "        percentages = counts / len(s)\n",
    "        entropy = -np.sum(p * np.log2(p) for p in percentages if p > 0)\n",
    "        return entropy\n",
    "\n",
    "    def _information_gain(self, parent, left_child, right_child):\n",
    "        num_left = len(left_child) / len(parent)\n",
    "        num_right = len(right_child) / len(parent)\n",
    "        return self._entropy(parent) - (num_left * self._entropy(left_child) + num_right * self._entropy(right_child))\n",
    "\n",
    "    def _best_split(self, X, y):\n",
    "        best_split = {}\n",
    "        best_info_gain = -1\n",
    "        n_rows, n_cols = X.shape\n",
    "\n",
    "        for f_idx in range(n_cols):\n",
    "            X_curr = X[:, f_idx]\n",
    "            unique_vals = np.unique(X_curr)\n",
    "            thresholds = (unique_vals[:-1] + unique_vals[1:]) / 2  # Midpoints as thresholds\n",
    "\n",
    "            for threshold in thresholds:\n",
    "                mask = X_curr <= threshold\n",
    "                y_left, y_right = y[mask], y[~mask]\n",
    "\n",
    "                if len(y_left) > 0 and len(y_right) > 0:\n",
    "                    gain = self._information_gain(y, y_left, y_right)\n",
    "                    if gain > best_info_gain:\n",
    "                        best_split = {\n",
    "                            'feature_index': f_idx,\n",
    "                            'threshold': threshold,\n",
    "                            'mask_left': mask,\n",
    "                            'gain': gain\n",
    "                        }\n",
    "                        best_info_gain = gain\n",
    "        return best_split\n",
    "\n",
    "    def _build(self, X, y, depth=0):\n",
    "        if len(y) >= self.min_samples_split and depth <= self.max_depth:\n",
    "            best = self._best_split(X, y)\n",
    "            if best.get('gain', 0) > 0:\n",
    "                left = self._build(X[best['mask_left']], y[best['mask_left']], depth + 1)\n",
    "                right = self._build(X[~best['mask_left']], y[~best['mask_left']], depth + 1)\n",
    "                return Node(feature=best['feature_index'], threshold=best['threshold'],\n",
    "                            data_left=left, data_right=right, gain=best['gain'])\n",
    "        return Node(value=Counter(y).most_common(1)[0][0])\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.root = self._build(X, y)\n",
    "\n",
    "    def _predict(self, x, tree):\n",
    "        if tree.value is not None:\n",
    "            return tree.value\n",
    "        if x[tree.feature] <= tree.threshold:\n",
    "            return self._predict(x, tree.data_left)\n",
    "        return self._predict(x, tree.data_right)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return [self._predict(x, self.root) for x in X]\n",
    "\n",
    "\n",
    "class RandomForest_manual:\n",
    "    def __init__(self, num_trees=25, min_samples_split=2, max_depth=5):\n",
    "        self.num_trees = num_trees\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.decision_trees = []\n",
    "\n",
    "    @staticmethod\n",
    "    def _sample(X, y):\n",
    "        np.random.seed(42)\n",
    "        n_rows = X.shape[0]\n",
    "        indices = np.random.choice(n_rows, size=n_rows, replace=True)\n",
    "        X_sample, y_sample = X[indices], y[indices]\n",
    "        \n",
    "        # Menghapus dimensi channel tambahan (C=1)\n",
    "        X_sample = np.squeeze(X_sample)  # Menghapus dimensi 1\n",
    "        print(f\"Sampled X shape after squeeze: {X_sample.shape}\")  # Debugging\n",
    "        print(f\"Sampled y shape: {y_sample.shape}\")  # Debugging\n",
    "        return X_sample, y_sample\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def fit_tree(self, X, y):\n",
    "        print(f\"Fitting tree with X shape: {X.shape}, y shape: {y.shape}\")  # Debugging\n",
    "        tree = DecisionTree(min_samples_split=self.min_samples_split, max_depth=self.max_depth)\n",
    "        tree.fit(X, y)\n",
    "        return tree\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        \n",
    "        # Menghapus dimensi ekstra jika ada\n",
    "        X = np.squeeze(X)  # Pastikan bentuknya adalah (n_samples, n_features)\n",
    "        \n",
    "        print(f\"Shape of X before training: {X.shape}\")  # Debugging\n",
    "        print(f\"Shape of y: {y.shape}\")  # Debugging\n",
    "        \n",
    "        self.decision_trees = Parallel(n_jobs=-1)(\n",
    "            delayed(self.fit_tree)(*self._sample(X, y)) for _ in range(self.num_trees)\n",
    "        )\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        tree_predictions = np.array([tree.predict(X) for tree in self.decision_trees])\n",
    "        predictions = [Counter(tree_predictions[:, i]).most_common(1)[0][0] for i in range(X.shape[0])]\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "kJ1FYFVSlPT1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X before training: (18436, 900)\n",
      "Shape of y: (18436,)\n",
      "Sampled X shape after squeeze: (18436, 900)\n",
      "Sampled y shape: (18436,)\n",
      "Sampled X shape after squeeze: (18436, 900)\n",
      "Sampled y shape: (18436,)\n",
      "Sampled X shape after squeeze: (18436, 900)\n",
      "Sampled y shape: (18436,)\n",
      "Sampled X shape after squeeze: (18436, 900)\n",
      "Sampled y shape: (18436,)\n",
      "Sampled X shape after squeeze: (18436, 900)\n",
      "Sampled y shape: (18436,)\n",
      "Sampled X shape after squeeze: (18436, 900)\n",
      "Sampled y shape: (18436,)\n",
      "Sampled X shape after squeeze: (18436, 900)\n",
      "Sampled y shape: (18436,)\n",
      "Sampled X shape after squeeze: (18436, 900)\n",
      "Sampled y shape: (18436,)\n",
      "Sampled X shape after squeeze: (18436, 900)\n",
      "Sampled y shape: (18436,)\n",
      "Sampled X shape after squeeze: (18436, 900)\n",
      "Sampled y shape: (18436,)\n",
      "Sampled X shape after squeeze: (18436, 900)\n",
      "Sampled y shape: (18436,)\n",
      "Sampled X shape after squeeze: (18436, 900)\n",
      "Sampled y shape: (18436,)\n",
      "Sampled X shape after squeeze: (18436, 900)\n",
      "Sampled y shape: (18436,)\n",
      "Sampled X shape after squeeze: (18436, 900)\n",
      "Sampled y shape: (18436,)\n",
      "Sampled X shape after squeeze: (18436, 900)\n",
      "Sampled y shape: (18436,)\n",
      "Sampled X shape after squeeze: (18436, 900)\n",
      "Sampled y shape: (18436,)\n",
      "Sampled X shape after squeeze: (18436, 900)\n",
      "Sampled y shape: (18436,)\n",
      "Sampled X shape after squeeze: (18436, 900)\n",
      "Sampled y shape: (18436,)\n",
      "Sampled X shape after squeeze: (18436, 900)\n",
      "Sampled y shape: (18436,)\n",
      "Sampled X shape after squeeze: (18436, 900)\n",
      "Sampled y shape: (18436,)\n",
      "Sampled X shape after squeeze: (18436, 900)\n",
      "Sampled y shape: (18436,)\n",
      "Sampled X shape after squeeze: (18436, 900)\n",
      "Sampled y shape: (18436,)\n",
      "Sampled X shape after squeeze: (18436, 900)\n",
      "Sampled y shape: (18436,)\n",
      "Sampled X shape after squeeze: (18436, 900)\n",
      "Sampled y shape: (18436,)\n",
      "Sampled X shape after squeeze: (18436, 900)\n",
      "Sampled y shape: (18436,)\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForest_manual(num_trees= 25)\n",
    "# rf = RandomForest_manual(num_trees= 25, min_sample_split = 2, max_depth = 5)\n",
    "rf.fit(x_train, y_train_encoded)\n",
    "y_pred2 = rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.17      0.17       571\n",
      "           1       0.50      0.02      0.03       111\n",
      "           2       0.18      0.11      0.13       571\n",
      "           3       0.30      0.45      0.36       571\n",
      "           4       0.24      0.26      0.25       571\n",
      "           5       0.20      0.15      0.17       571\n",
      "           6       0.32      0.44      0.37       571\n",
      "\n",
      "    accuracy                           0.25      3537\n",
      "   macro avg       0.27      0.23      0.21      3537\n",
      "weighted avg       0.25      0.25      0.24      3537\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Menghitung classification report\n",
    "report = classification_report(y_test_encoded, y_pred2)\n",
    "\n",
    "# Menampilkan classification report\n",
    "print(\"Classification Report:\\n\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "g9C4P14dmHTe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model berhasil disimpan ke random_forest_model.joblib\n"
     ]
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "# Menyimpan model ke file .joblib\n",
    "dump(rf, 'random_forest_model.joblib')\n",
    "print(\"Model berhasil disimpan ke random_forest_model.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
